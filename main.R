# Packages ---------------------------------------------------------------
suppressPackageStartupMessages(install.packages('ff', quietly = TRUE))

# Libraries ---------------------------------------------------------------

## API calls with R
suppressPackageStartupMessages(library(httr))
## Data wrangling - equivalent to pandas + piping
suppressPackageStartupMessages(library(dplyr, quietly = TRUE))
suppressPackageStartupMessages(library(data.table, quietly = TRUE))
## Json parsinf (fromJson)
suppressPackageStartupMessages(library(jsonlite, quietly = TRUE))
## Functional programming - map, reduce functions
suppressPackageStartupMessages(library(purrr, quietly = TRUE))
## Reading and writing CSV files and other formats (--ditch this if ff solves the problem)
suppressPackageStartupMessages(library(readr, quietly = TRUE))
## Parallel multithreading processing
#suppressPackageStartupMessages(library(parallel, quietly = TRUE))
## Big memory handling - saves objects to disk so it does not eat RAM
suppressPackageStartupMessages(library(ff, quietly = TRUE))
## Operations with dates
suppressPackageStartupMessages(library(lubridate, quietly = TRUE))

# Input config ------------------------------------------------------------


## initialize keboola application this saves all user inputs from the extractor to variables
library('keboola.r.docker.application')
app <- DockerApplication$new('/data/')

app$readConfig()
## Daktela username
user<-app$getParameters()'$user'
## Daktela password
pwd<-app$getParameters()$'#pwd'
## Daktela server url
url<-app$getParameters()'url'
## The date
days_past<-app$getParameters()$'from'

## Create the date from where we take data
days_past<-ifelse(is.null(days_past),1,as.numeric(days_past))

from<-Sys.Date()-days_past

#********************Tereza to apply***********************
# csvFilePath<-paste0("/data/out/tables/",endpoint[[3]],".csv")
#    write_csv(data,csvFilePath)
#    #PÅ™idat manifest file
#    app$writeTableManifest(csvFilePath,destination='')

#*********************Tereza end *********************
##Catch config errors
if(is.null(pwd) | is.null(user) | is.null(url) ) stop("invalid credentials or site URL")

## Retrieve token
token<-POST(paste0(url,"/api/v6/login.json"),body=list(password=pwd,username=user,only_token=1))%>%
  content("text",encoding = "UTF-8")%>%fromJSON(flatten=TRUE,simplifyDataFrame = TRUE)%>%.$result


# Function definition -----------------------------------------------------

#' Parse
#' Default parser for the JSON response of the Daktela API
#'
#' @param response
#'
#' @return dataframe

parse <-
  function(r) {
    res <- r %>% fromJSON(flatten = TRUE, simplifyDataFrame = TRUE) %>%
      .$result %>%
      .$data %>% select(-contains(".")) %>%
      #By default I drop all the objects that are nested
      .[, sapply(., class) != "list"] %>%
      as_data_frame
  }

#This function paginates through an endpoint in parallel and writes the result to the out bucket
#' Write Endporint
#' This function by default paginates through and endpoint a and writes the resulting rows to a CSV file
#' Since some enpoints returns nested lists the function ignores those and returns just the uppermost level
#' as dataframe. If this happens it is necessary to define an iterator function which takes desired elements
#' from the nested lists and puts them in the uppermost level.
#'
#' @param endpoint endpoint attribute list for the api call containting:
#'  endpoint url [1],
#'  endpoint time filter atribute name [2],
#'  endpoint name [3]
#' @param token token generated by calling /api/v6/login.json
#' @param from the date used to filter data from until now.
#' @param limit maximum number of lines to be returned. The default value is 1000
#' @param iterator function used to parse data when nonstandart rules apply for the particular endpoint
#'
#' @return prints a message stating if the task is completed
#' @export csv file.
#'
#' @examples
#'
write_endpoint<-function(endpoint,token,from=NULL,limit=1000,iterator=parse){

  #Record task start time
  a<-Sys.time()

  ## Looking wether the time filter is applied and changing the endpoint url accordingly
  endpoint_url<-if_else(is.null(from) | endpoint[[2]]==FALSE,
                       #FALSE - without filter
                       endpoint[[1]],
                       #TRUE - with time filter
                       paste0(endpoint[[1]],"?filter[field]=",endpoint[[2]],"&filter[operator]=gte&filter[value]=",from))

  ## Filtering example /api/v6/contacts.json?filter[field]=Time&filter[operator]=gte&filter[value]=2018-01-01

  #create the endpoint url
  call<-paste0(url,endpoint_url)

  #get the size of the list
  total<-GET(call,query=list(accessToken=token,skip=0,take=1))%>%
    content("text",encoding = "UTF-8")%>%fromJSON(flatten=TRUE,simplifyDataFrame = FALSE)%>%.$result%>%.$total

  #continue only if size of the list >0
  if(total<1){
    write(paste0("Report ",endpoint[[3]], " is empty for selected criteria "), stdout())
    rows_fetched<-0
  } else {

  #creating a sequence reflecting pagination limits
  i=seq(0,total,by = limit)
  cores<-parallel::detectCores()-1

  rows_fetched<-map(i,function(i){
    #Call the api
    res<-GET(call,query=list(accessToken=token,skip=i,take=limit))%>%
      #Return the json
      content("text",encoding = "UTF-8")%>%
      #Use the parse function
      parse
    #If i = 0 then initialize the file else append the csv using fwrite from data.table in order to not waste RAM
    fwrite(res,paste0("out/tables/",endpoint[[3]],".csv"),append = ifelse(i>0,TRUE,FALSE))%>%unlist%>%sum

    nrow(res)
  })%>%unlist%>%as.numeric%>%sum()

  }

    #Writing a message to the console
    b<-Sys.time()
    write(paste0("Task ",endpoint[[3]],": ",rows_fetched ,"/",total," records extracted, task duration: ",time<-round(difftime(b,a,units="secs")%>%as.numeric,2)," s"), stdout())

    #Process log info
    ## Check if out_log.csv exists
    logfile_created<-file.exists("out/tables/out_log.csv")

    log<-data_frame("date"=Sys.time(),"endpoint"=endpoint[[3]],"exported_records"=total,"extraction_time"=time)
    fwrite(log,"out/tables/out_log.csv",append=logfile_created)
  }


# Extraction of endpoints -------------------------------------------------
#This section defines the subroutines used for particular endpoints.

## Activities
activities<-list("/api/v6/activities.json","time","activities")
write_endpoint(activities,token,from = from)

## ActivitiesCall
activitiesCall<-list("/api/v6/activitiesCall.json","call_time","activitiesCall")

### Iterator function for Activities Call transformation
iterator_activitiesCall<-function(r){
  clean<-r%>%fromJSON(flatten=TRUE,simplifyDataFrame = TRUE)%>%.$result%>%.$data%>%select(-contains("."))%>%as_data_frame
  df<-r%>%fromJSON(flatten=FALSE,simplifyDataFrame = TRUE)%>%.$result%>%.$data
  df<-data_frame(queue=map(df,"name")$id_queue,
                 queue_title=map(df,"title")$id_queue,
                 agent_title=map(df,"title")$id_agent
  )
  out<-clean%>%bind_cols(df)
}
write_endpoint(activitiesCall,token,from = from,iterator = iterator_activitiesCall)

## ActivitiesEmail
activitiesEmail<-list("/api/v6/activitiesEmail.json","time","activitiesEmail")

### Iterator function for Activities Email transformation
iterator_activitiesEmail<-function(r){
  clean<-r%>%fromJSON(flatten=TRUE,simplifyDataFrame = TRUE)%>%.$result%>%.$data%>%select(-contains("."))%>%as_data_frame
  df<-r%>%fromJSON(flatten=FALSE,simplifyDataFrame = TRUE)%>%.$result%>%.$data
  df<-data_frame(queue_title=map(df,"title")$queue
  )
  out<-clean%>%bind_cols(df)%>%select(-files)
}
write_endpoint(activitiesEmail,token,from = from,iterator = iterator_activitiesEmail)

## ActivitiesChat
activitiesChat<-list("/api/v6/activitiesChat.json","time","activitiesChat")
iterator_activitiesChat<-function(r){
  clean<-r%>%fromJSON(flatten=TRUE,simplifyDataFrame = TRUE)%>%.$result%>%.$data%>%select(-contains("."))%>%as_data_frame
  df<-r%>%fromJSON(flatten=FALSE,simplifyDataFrame = TRUE)%>%.$result%>%.$data
  df<-data_frame(queue_title=map(df,"title")$queue,
                 referer=map(df,"referer")$options
  )
  out<-clean%>%bind_cols(df)
}
write_endpoint(activitiesChat,token,from = from,iterator = iterator_activitiesChat)

## Accounts
accounts<-list("/api/v6/accounts.json",FALSE,"accounts")
write_endpoint(accounts,token,from = from,iterator = FALSE)

## Groups
groups<-list("/api/v6/groups.json",FALSE,"groups")
write_endpoint(groups,token,from = from,iterator = FALSE)

## Pauses
pauses<-list("/api/v6/pauses.json",FALSE,"pauses")
write_endpoint(pauses,token,from = from,iterator = FALSE)

## Queues
queues<-list("/api/v6/queues.json",FALSE,"queues")
write_endpoint(queues,token,from = from,iterator = FALSE)

## Statuses
statuses<-list("/api/v6/statuses.json",FALSE,"statuses")
write_endpoint(statuses,token,from = from,iterator = FALSE)

## Templates
templates<-list("/api/v6/templates.json",FALSE,"templates")
write_endpoint(templates,token,from = from,iterator = FALSE)

## Tickets
tickets<-list("/api/v6/tickets.json","edited","tickets")
write_endpoint(tickets,token,from = from,iterator = FALSE)

### These endpoints are commented as they may contain personal info
# contacts<-list("/api/v6/contacts.json","edited")
# crmRecords<-list("/api/v6/crmRecords.json","edited")
# campaignRecords<-list("/api/v6/campaignsRecords.json","edited")
# users<-list("/api/v6/users.json",FALSE)
